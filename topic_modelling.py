# -*- coding: utf-8 -*-
"""Topic_modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C-w8ImcLnREktnxfitbf-NTZ7FIwHfsd
"""

import nltk
import gensim
import re
import math
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from gensim.models import LdaModel
import matplotlib.pyplot as plt
from nltk.tokenize import word_tokenize
from collections import defaultdict
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
import pandas as pd
import numpy as np
from gensim import corpora
import string
!pip install datasets
from datasets import load_dataset

dataset = load_dataset("zeroshot/twitter-financial-news-topic")
df = pd.DataFrame(dataset['train']) # Accessing the 'train' split of the dataset
df.head()

#df = pd.read_csv("hf://datasets/lukecarlate/english_finance_news/english_financial_news_v2.csv")
#df.head()

df.shape

# Ensure df is a DataFrame before dropping columns
if isinstance(df, pd.DataFrame):
    drop_col = ["label"]
    df = df.drop(drop_col, axis = 1)
    df.head() # Verify the changes
else:
    print("df is not a Pandas DataFrame.")

df.info()

# Convert to lowercase
df['text'] = df['text'].str.lower()
df['text'].head()

# Remove punctuation from text
import string
df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))
df['text'].head()

# Stop Words Removal
stop_word = stopwords.words('english')
df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_word)]))
df['text'].head()

#Tokenization
df['text'] = df['text'].apply(lambda x: x.split())
df.head()

# Lemmatization
lemmatizer = WordNetLemmatizer()
tokens_lemmatized = [[lemmatizer.lemmatize(word) for word in sentence] for sentence in df['text']]
print("Lemmatized Tokens:", tokens_lemmatized)

# Create a dictionary and corpus for LDA
dictionary = corpora.Dictionary(df['text'])
corpus = [dictionary.doc2bow(tokens) for tokens in df['text']]

import multiprocessing

def compute_perplexity_values(dictionary, corpus, limit, start=2, step=1):
    num_cores = multiprocessing.cpu_count()

    with multiprocessing.Pool(num_cores) as pool:
        perplexity_values = pool.starmap(
            _compute_perplexity,
            [(corpus, num_topics, dictionary) for num_topics in range(start, limit, step)]
        )

    return perplexity_values

def _compute_perplexity(corpus, num_topics, dictionary):
    model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=5)
    return model.log_perplexity(corpus)

# Run LDA for different number of topics
start, limit, step = 2, 10, 1
perplexity_values = compute_perplexity_values(dictionary, corpus, limit, start, step)

# Plot the perplexity scores
x = range(start, limit, step)
plt.plot(x, perplexity_values)
plt.xlabel("Number of Topics")
plt.ylabel("Perplexity Score")
plt.title("Elbow Method for Topics")
plt.show()

from gensim import corpora
from gensim.models import LdaModel

doc = corpora.Dictionary(df['text'])
corpus = [doc.doc2bow(tokens) for tokens in df['text']]

# Train LDA model
lda_model = LdaModel(corpus, num_topics=3, id2word=doc, passes=15)

# Display topics
topics = lda_model.print_topics(num_words=6)
print("\nTopics:")
for topic in topics:
    print(topic)

# Get document-topic matrix
document_topic_matrix = lda_model.get_document_topics(corpus)

# Initialize topic-word matrix
topic_word_matrix = lda_model.get_topics()

# Display topics
topics = lda_model.print_topics(num_words=3)
print("\nTopics:")
for topic in topics:
    print(topic)

# Display document-topic matrix
print("\nDocument-Topic Matrix:")
for i, doc_topics in enumerate(document_topic_matrix):
    print(f"Document {i}: {doc_topics}")

# Display topic-word matrix
print("\nTopic-Word Matrix:")
for i, topic_words in enumerate(topic_word_matrix):
    top_words = ', '.join([doc[word_id] for word_id in np.argsort(-topic_words)[:4]])
    print(f"Topic {i}: {top_words}")

# Generate word clouds for topics
from wordcloud import WordCloud
import matplotlib.pyplot as plt

for i, topic in enumerate(topic_word_matrix):
    plt.figure()
    # Use 'doc' instead of 'dictionary' to access word mappings
    wordcloud = WordCloud(width=800, height=400, background_color ='black').fit_words({doc[word_id]: topic_word_matrix[i][word_id] for word_id in range(len(doc))})
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Topic {i}")
    plt.show()

#Evaluation matrix
# Print the perplexity values
print("Perplexity values:")
for m, perplexity in zip(x, perplexity_values):
    print("Num Topics =", m, " has Perplexity Score of", round(perplexity, 4))